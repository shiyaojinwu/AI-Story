# 模型端项目文档
# 📋 文档概述
本文档旨在为“故事到视频”生成项目中的模型端提供全面、清晰的设计、部署与维护指南。
涵盖模型选型、部署架构、接口定义、任务流程、性能优化与异常处理等核心内容。

### 🎯 一、模型端核心职责
故事结构化解析：将用户输入的文本故事，拆解为结构化的分镜序列。

图像生成：根据每个分镜的文本描述（Prompt），生成对应的关键帧图像。

语音合成：将分镜旁白文本转换为语音文件。

视频动态化：将静态关键帧图像转化为动态视频片段。

### 🧠 二、模型选型与部署
#### 模型类型
| 模型类型         | 具体模型               | 部署方式                     | 核心能力                               | 资源要求                               |
|------------------|------------------------|------------------------------|----------------------------------------|----------------------------------------|
| LLM（大语言模型）| [Qwen2.5-0.5B](https://modelscope.cn/models/qwen/Qwen2.5-7B-Instruct/summary)           | transformers        | 故事分镜生成、旁白文案生成、结构化JSON输出 | 内存中等，支持量化                 |
| 文生图（Text-to-Image）| [stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) | Diffusers| 根据Prompt生成高质量关键帧图像         | GPU（显存≥8GB），支持CPU模式（较慢） |
| TTS（文本转语音）| [CosyVoice](https://github.com/FunAudioLLM/CosyVoice)        | CosyVoice2         | 将旁白文本合成为自然语音               | 内存占用低（显存1GB）                     |
| 图生视频 | [Image-to-Video](https://www.modelscope.cn/models/iic/Image-to-Video/summary) | Diffusers| 将静态图像转为短视频片段               | GPU要求较高（显存≥16GB）                 |

#### 部署架构
环境：Linux服务器

通信：通过内网穿透将本地模型服务暴露给公网服务端。

服务化：每个模型封装为独立的HTTP API服务，便于服务端调用与维护。

### ⚙️ 三、性能优化与稳定性
量化：对LLM、SD模型进行INT8量化，降低显存与计算开销。

混合精度：使用混合精度优化图生视频模型的推理速度和占用内存。

重试机制：对暂时性失败（如GPU内存不足）进行自动重试（最多3次）。

轮询模型服务：提供接口轮询模型服务状态。

日志记录：详细记录每次生成请求的参数、耗时与结果，便于排查。

### ✅ 四、验收标准

图像生成 ≤ 10s

音频生成 ≤ 30s

视频生成 ≤ 15GB
